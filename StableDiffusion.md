# Stable Diffusion Governance / Usage

# Preamble

## Australia’s AI Ethics Principles

The Australian government has authored a set of voluntary industry AI Ethics Principles available at https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics-principles 

**Suggested benefits of adopting these**

* build public trust in your product or organisation
* drive consumer loyalty in your AI-enabled services
* positively influence outcomes from AI
* ensure all Australians benefit from this transformative technology.

**"Principles at a glance"**

* Human, societal and environmental wellbeing: AI systems should benefit individuals, society and the environment.
* Human-centred values: AI systems should respect human rights, diversity, and the autonomy of individuals.
* Fairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.
* Privacy protection and security: AI systems should respect and uphold privacy rights and data protection, and ensure the security of data.
* Reliability and safety: AI systems should reliably operate in accordance with their intended purpose.
* Transparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.
* Contestability: When an AI system significantly impacts a person, community, group or environment, there should be a timely process to allow people to challenge the use or outcomes of the AI system.
* Accountability: People responsible for the different phases of the AI system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.


## Observations / Definition

1. This document is intended as a foundation for governing ethical use of Stable Diffusion and other AI Image Generation tools ("the tools") which rely on a trained dataset of source real-world images, that reproduce stylistic and aesthetic elements present (latent) in the source dataset.
2. These tools can generate novel images from text prompts, or unconstrained.
3. The datasets for these tools are very large **_(ref)_** and it is not standard practice to license these images. They are collected from "in the wild", with  metadata about their content, and possibly author. 
4. Training these systems takes considerable effort, time, energy, money, and for large models creating them is outside of the scope of the hobbyist or individual. **_(ref)_**
5. Masking or "Infilling" can selectively generate content that fit with existing parts of an image, for example keeping a face and generating a new scenarious or outfit around them based on a prompt. 
6. While there is often the claim or suggestion that what they generate is **neccesserily unique** (e.g. https://thispersondoesnotexist.com/ ), there is nothing in the way the images are generated that **guarantees** the outcomes are novel or unique.

## Positives / Benefitual use of Technology

1. Convincing photorealistic images based on novel prompts. 
2. Aesthetically pleasing images representing novel scenarios with an existing artistic style.

### Use Cases

1. These tools can be used as part of an aleatory practice (involving chance/indeterminacy/randomness, such as throwing dice or drawing tarot cards) to inspire the creation of entirely novel ideas. (But the dice are loaded - maybe more like asking advice of a group of interested parties?)

## Negatives / Molevolent use of Technology

1. Replacing the need for working artists/ creatives, and making even more precarious and unsustainable to be an artist. This will have a chilling effect / homogenise aesthetics, without new styles or ways of representing the world being fed into the system.
2. These tools tend to reproduce tropes / cliches / social norms / discrimination
3. They embody opaque editorial and censorship decisions of the companies that created them

### Interdictions

1. Creation of culturally specific styles or images.
2. The use of the tools to knowingly substitute the fair work of an artist?? surely this is most of the time)?
3. The creation of images for deliberate misinformation where there is not a parody or clear illustrative / hypothetical purpose. 
4. Use of the tools for infilling real photos / people into sexual or misrepresentative sitations.

## Guidelines and reflections on Use

1. Outcomes are based on the work of others, who are collaborators deserving of remuneration (are they deserving of moral rights?)  implication: rev share, if identified… (attempt to identify?)
2. I am the “client” responding to creative ideas from another, based on a “brief” (prompt). This doesn’t mean I’m not also a creative element in the project, but it doesn’t necessarily mean I am, as in any similar scenario.
3. (re chilling effect) These generated outcomes will tend to existing looks. Up to us to bring the value of innovation in the story/or how they are used.
4. Also a required need for aesthetic innovation?! Project must(?) give more back or push look/ideas further?
5. Where possible try to train own, based on completely voluntary and controlled dataset.





